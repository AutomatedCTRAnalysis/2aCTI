{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d47514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "     \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "\n",
    "import pickle \n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "from plotly.subplots import make_subplots\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "import flair\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223a2970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /homes/lgf21/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa06fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c08ed5",
   "metadata": {},
   "source": [
    "# Opening Files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be213c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle without lemmatisation: \n",
    "\n",
    "with open('merged_data_no_duplicates.pickle', 'rb') as handle:\n",
    "    (X_train_text, X_test_text, Y_train, Y_test, _, _) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652d7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle lemmatised: \n",
    "\n",
    "#with open('merged_data_lemma.pickle', 'rb') as handle:\n",
    "#    (X_train_text, X_test_text, Y_train, Y_test, _, _) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419988bd",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad08c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35765648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call method\n",
    "from methods import feature_extraction, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "452f5136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 0], dtype='object')\n",
      "Index(['index', 0], dtype='object')\n",
      "Index(['index', 0], dtype='object')\n",
      "Index(['index', 0], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([1,2,3,4]).reset_index().apply(lambda row: print(row.index),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e56011",
   "metadata": {},
   "source": [
    "## Count Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b21e555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test = feature_extraction('CountVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e5363",
   "metadata": {},
   "source": [
    "## TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2aec33c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = feature_extraction('TfIdfVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597d0e7",
   "metadata": {},
   "source": [
    "## word2vec Google news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b664d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_google = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cf8a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_extraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extraction\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m, X_train_text, X_test_text, embedding_type \u001b[38;5;241m=\u001b[39m w2v_google, weighted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_extraction' is not defined"
     ]
    }
   ],
   "source": [
    "#X_train, X_test = feature_extraction('embedding', X_train_text, X_test_text, embedding_type = w2v_google, weighted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2d2c0",
   "metadata": {},
   "source": [
    "## Glove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ebd6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glv = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45498eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2072it [06:26,  5.36it/s]\n",
      "441it [01:04,  6.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test = feature_extraction('embedding', X_train_text, X_test_text, embedding_type = glv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d1938",
   "metadata": {},
   "source": [
    "## Trained word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae45c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9f0263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2072it [01:34, 22.02it/s]\n",
      "441it [00:12, 34.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test = feature_extraction(\"embedding\", X_train_text, X_test_text, embedding_type = w2v, weighted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca4f74",
   "metadata": {},
   "source": [
    "# Classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba1fd1",
   "metadata": {},
   "source": [
    "## Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e45cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = OneVsRestClassifier(MultinomialNB())\n",
    "naive_bayes_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pd.DataFrame(naive_bayes_classifier.predict_proba(X_test), columns = Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02dddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_proba > 0.005).astype(int) # if increase threshold, recall decreases and precision (could) increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a00939",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5572db",
   "metadata": {},
   "source": [
    "## SVC:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a4503",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b998f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(class_weight='balanced', dual=False,\n",
       "                                        random_state=42),\n",
       "                    n_jobs=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test: First delete techniques less than 9 \n",
    "# We fix the random state to have the same dataset in our different tests\n",
    "\n",
    "sv_classifier = OneVsRestClassifier(LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 1000, class_weight = 'balanced', random_state=42), n_jobs = 1)\n",
    "sv_classifier.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0a294f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(sv_classifier.predict(X_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d284583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>macro precision</td>\n",
       "      <td>0.624793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro precision</td>\n",
       "      <td>0.663291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro recall</td>\n",
       "      <td>0.607837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro recall</td>\n",
       "      <td>0.642682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro fscore</td>\n",
       "      <td>0.620334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro fscore</td>\n",
       "      <td>0.659064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric    result\n",
       "0  macro precision  0.624793\n",
       "1  micro precision  0.663291\n",
       "2     macro recall  0.607837\n",
       "3     micro recall  0.642682\n",
       "4     macro fscore  0.620334\n",
       "5     micro fscore  0.659064"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4114e",
   "metadata": {},
   "source": [
    "## Multi-label KNN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5b28ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = MLkNN(k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works old version sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfdb2283",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m, Y_train\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# predict\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mvalues)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# train\n",
    "knn.fit(X_train.values, Y_train.values)\n",
    "\n",
    "# predict\n",
    "predictions = knn.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eee7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7c220",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "893f1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimension using pca: \n",
    "\n",
    "pca = PCA(n_components=75)\n",
    "pca.fit(X_train)\n",
    "pca_result = pca.transform(X_train)\n",
    "x_test_result = pca.transform(X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92d73bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg = OneVsRestClassifier(LogisticRegression(random_state=0, multi_class='multinomial', solver='lbfgs', max_iter = 1000)).fit(X_train, Y_train)\n",
    "\n",
    "predictions = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fcddd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>macro precision</td>\n",
       "      <td>0.585619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro precision</td>\n",
       "      <td>0.625399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro recall</td>\n",
       "      <td>0.605949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro recall</td>\n",
       "      <td>0.640229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro fscore</td>\n",
       "      <td>0.588785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro fscore</td>\n",
       "      <td>0.628310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric    result\n",
       "0  macro precision  0.585619\n",
       "1  micro precision  0.625399\n",
       "2     macro recall  0.605949\n",
       "3     micro recall  0.640229\n",
       "4     macro fscore  0.588785\n",
       "5     micro fscore  0.628310"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e00008",
   "metadata": {},
   "source": [
    "## DT AdaBoost: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6501ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_adaboost = OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=0)).fit(X_train, Y_train)\n",
    "predictions_ada = dt_adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "662a180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>macro precision</td>\n",
       "      <td>0.430559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro precision</td>\n",
       "      <td>0.524390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro recall</td>\n",
       "      <td>0.242943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro recall</td>\n",
       "      <td>0.316435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro fscore</td>\n",
       "      <td>0.359167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro fscore</td>\n",
       "      <td>0.463473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric    result\n",
       "0  macro precision  0.430559\n",
       "1  micro precision  0.524390\n",
       "2     macro recall  0.242943\n",
       "3     micro recall  0.316435\n",
       "4     macro fscore  0.359167\n",
       "5     micro fscore  0.463473"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(predictions_ada, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e2b88",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2a1e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8956235",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'sklearn.multiclass.OneVsRestClassifier'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/2aCTI/Notebook/../src/methods.py:114\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(Y_pred, Y_test)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation\u001b[39m(Y_pred, Y_test):\n\u001b[0;32m--> 114\u001b[0m     macro_precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     micro_precision \u001b[38;5;241m=\u001b[39m precision_score(Y_test, Y_pred, average \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m     macro_recall \u001b[38;5;241m=\u001b[39m recall_score(Y_test, Y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1757\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[1;32m   1629\u001b[0m     y_true,\n\u001b[1;32m   1630\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1637\u001b[0m ):\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1639\u001b[0m \n\u001b[1;32m   1640\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1544\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1348\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:329\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    330\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:329\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    330\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:259\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    256\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected sequence or array-like, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(x)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m callable(x\u001b[38;5;241m.\u001b[39mfit):\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# Don't get num_samples from an ensembles length!\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'sklearn.multiclass.OneVsRestClassifier'>"
     ]
    }
   ],
   "source": [
    "evaluation(predictions_rf, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd5cfe",
   "metadata": {},
   "source": [
    "# Classifer Chain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_model(model):\n",
    "    model_chain = ClassifierChain(model, order='random', random_state=0)\n",
    "    return model_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chain_model(mlp) # change model appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0364f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainModel = chain.fit(X_train.values, Y_train.values)\n",
    "predictions = chainModel.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf79bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fa2ee",
   "metadata": {},
   "source": [
    "# Neural Networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5ce5a",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d0a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=1, max_iter=300).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions_mlp, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccafb76",
   "metadata": {},
   "source": [
    "## Loading data from flair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c405b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fasttext_format_test.txt', 'w') as file:\n",
    "    for i in range(len(Y_test)):\n",
    "        file.write(' '.join(['__label__'+col for col in Y_test.columns if Y_test.iloc[i][col] == 1]) + ' ' + X_test_text.iloc[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21c576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 12:51:36,884 Reading data from .\n",
      "2022-08-08 12:51:36,885 Train: fasttext_format_train.txt\n",
      "2022-08-08 12:51:36,886 Dev: fasttext_format_test.txt\n",
      "2022-08-08 12:51:36,887 Test: fasttext_format_test.txt\n",
      "2022-08-08 12:51:38,199 Initialized corpus . (label type name is 'tactic')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flair.device = 'cpu'\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '.'\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus = ClassificationCorpus(data_folder,\n",
    "                                      test_file='fasttext_format_test.txt',\n",
    "                                      dev_file='fasttext_format_test.txt',\n",
    "                                      train_file='fasttext_format_train.txt',\n",
    "                                      label_type='tactic',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "368aad27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 12:51:40,957 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2152it [02:27, 14.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 12:54:08,354 Dictionary created for label 'tactic' with 13 values: TA0005 (seen 1237 times), TA0003 (seen 857 times), TA0002 (seen 756 times), TA0004 (seen 742 times), TA0011 (seen 688 times), TA0007 (seen 659 times), TA0006 (seen 487 times), TA0009 (seen 465 times), TA0008 (seen 312 times), TA0001 (seen 248 times), TA0010 (seen 199 times), TA0040 (seen 190 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# label to be predicted: \n",
    "label_type = 'tactic'\n",
    "# create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a83c9",
   "metadata": {},
   "source": [
    "## Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "191393bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 12:54:15,752 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 12:54:15,753 Model: \"TextClassifier(\n",
      "  (decoder): Linear(in_features=768, out_features=13, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): BCEWithLogitsLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): DistilBertModel(\n",
      "      (embeddings): Embeddings(\n",
      "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-08-08 12:54:15,753 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 12:54:15,757 Corpus: \"Corpus: 2152 train + 441 dev + 441 test sentences\"\n",
      "2022-08-08 12:54:15,757 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 12:54:15,758 Parameters:\n",
      "2022-08-08 12:54:15,759  - learning_rate: \"0.000050\"\n",
      "2022-08-08 12:54:15,759  - mini_batch_size: \"4\"\n",
      "2022-08-08 12:54:15,761  - patience: \"3\"\n",
      "2022-08-08 12:54:15,761  - anneal_factor: \"0.5\"\n",
      "2022-08-08 12:54:15,762  - max_epochs: \"10\"\n",
      "2022-08-08 12:54:15,763  - shuffle: \"True\"\n",
      "2022-08-08 12:54:15,764  - train_with_dev: \"False\"\n",
      "2022-08-08 12:54:15,765  - batch_growth_annealing: \"False\"\n",
      "2022-08-08 12:54:15,765 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 12:54:15,766 Model training base path: \"test_model\"\n",
      "2022-08-08 12:54:15,766 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 12:54:15,767 Device: cpu\n",
      "2022-08-08 12:54:15,767 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 12:54:15,768 Embeddings storage mode: none\n",
      "2022-08-08 12:54:15,769 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 12:58:20,519 epoch 1 - iter 53/538 - loss 0.17629689 - samples/sec: 0.91 - lr: 0.000005\n",
      "2022-08-08 13:02:24,388 epoch 1 - iter 106/538 - loss 0.15775508 - samples/sec: 0.92 - lr: 0.000010\n",
      "2022-08-08 13:06:43,708 epoch 1 - iter 159/538 - loss 0.14703178 - samples/sec: 0.88 - lr: 0.000015\n",
      "2022-08-08 13:10:20,359 epoch 1 - iter 212/538 - loss 0.14164802 - samples/sec: 1.05 - lr: 0.000020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 13:15:10,000 epoch 1 - iter 265/538 - loss 0.13728553 - samples/sec: 0.78 - lr: 0.000025\n",
      "2022-08-08 13:20:35,096 epoch 1 - iter 318/538 - loss 0.12886225 - samples/sec: 0.68 - lr: 0.000030\n",
      "2022-08-08 13:25:52,270 epoch 1 - iter 371/538 - loss 0.12128251 - samples/sec: 0.69 - lr: 0.000034\n",
      "2022-08-08 13:31:33,044 epoch 1 - iter 424/538 - loss 0.12119603 - samples/sec: 0.66 - lr: 0.000039\n",
      "2022-08-08 13:38:36,071 epoch 1 - iter 477/538 - loss 0.12369767 - samples/sec: 0.58 - lr: 0.000044\n",
      "2022-08-08 13:46:25,653 epoch 1 - iter 530/538 - loss 0.12495428 - samples/sec: 0.50 - lr: 0.000049\n",
      "2022-08-08 13:47:31,825 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 13:47:31,826 EPOCH 1 done: loss 0.1250 - lr 0.000049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [04:58<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 13:52:30,917 Evaluating as a multi-label problem: True\n",
      "2022-08-08 13:52:30,991 DEV : loss 0.17610898613929749 - f1-score (micro avg)  0.4264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 13:53:22,107 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 13:53:22,110 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 14:00:26,026 epoch 2 - iter 53/538 - loss 0.13622628 - samples/sec: 0.53 - lr: 0.000049\n",
      "2022-08-08 14:05:02,425 epoch 2 - iter 106/538 - loss 0.13246766 - samples/sec: 0.82 - lr: 0.000049\n",
      "2022-08-08 14:09:52,645 epoch 2 - iter 159/538 - loss 0.13070467 - samples/sec: 0.79 - lr: 0.000048\n",
      "2022-08-08 14:14:28,556 epoch 2 - iter 212/538 - loss 0.12934613 - samples/sec: 0.81 - lr: 0.000048\n",
      "2022-08-08 14:19:11,842 epoch 2 - iter 265/538 - loss 0.12804143 - samples/sec: 0.80 - lr: 0.000047\n",
      "2022-08-08 14:23:58,414 epoch 2 - iter 318/538 - loss 0.12716532 - samples/sec: 0.81 - lr: 0.000047\n",
      "2022-08-08 14:28:38,576 epoch 2 - iter 371/538 - loss 0.12669700 - samples/sec: 0.81 - lr: 0.000046\n",
      "2022-08-08 14:33:19,228 epoch 2 - iter 424/538 - loss 0.12637297 - samples/sec: 0.81 - lr: 0.000046\n",
      "2022-08-08 14:38:10,515 epoch 2 - iter 477/538 - loss 0.12615398 - samples/sec: 0.79 - lr: 0.000045\n",
      "2022-08-08 14:42:47,357 epoch 2 - iter 530/538 - loss 0.12539146 - samples/sec: 0.80 - lr: 0.000045\n",
      "2022-08-08 14:43:27,565 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 14:43:27,566 EPOCH 2 done: loss 0.1252 - lr 0.000045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:14<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 14:46:42,657 Evaluating as a multi-label problem: True\n",
      "2022-08-08 14:46:42,694 DEV : loss 0.11544405668973923 - f1-score (micro avg)  0.2572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 14:47:09,132 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 14:47:09,135 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 14:51:54,196 epoch 3 - iter 53/538 - loss 0.12420942 - samples/sec: 0.81 - lr: 0.000044\n",
      "2022-08-08 14:56:35,202 epoch 3 - iter 106/538 - loss 0.12237646 - samples/sec: 0.80 - lr: 0.000043\n",
      "2022-08-08 15:01:25,641 epoch 3 - iter 159/538 - loss 0.12321632 - samples/sec: 0.79 - lr: 0.000043\n",
      "2022-08-08 15:06:09,192 epoch 3 - iter 212/538 - loss 0.12439998 - samples/sec: 0.80 - lr: 0.000042\n",
      "2022-08-08 15:10:50,613 epoch 3 - iter 265/538 - loss 0.12311139 - samples/sec: 0.80 - lr: 0.000042\n",
      "2022-08-08 15:15:35,519 epoch 3 - iter 318/538 - loss 0.12192921 - samples/sec: 0.80 - lr: 0.000041\n",
      "2022-08-08 15:20:06,519 epoch 3 - iter 371/538 - loss 0.12223887 - samples/sec: 0.82 - lr: 0.000041\n",
      "2022-08-08 15:24:55,665 epoch 3 - iter 424/538 - loss 0.12251830 - samples/sec: 0.80 - lr: 0.000040\n",
      "2022-08-08 15:29:26,821 epoch 3 - iter 477/538 - loss 0.12154768 - samples/sec: 0.82 - lr: 0.000040\n",
      "2022-08-08 15:34:01,033 epoch 3 - iter 530/538 - loss 0.12188292 - samples/sec: 0.82 - lr: 0.000039\n",
      "2022-08-08 15:34:42,371 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 15:34:42,372 EPOCH 3 done: loss 0.1222 - lr 0.000039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:11<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 15:37:54,368 Evaluating as a multi-label problem: True\n",
      "2022-08-08 15:37:54,396 DEV : loss 0.11832620203495026 - f1-score (micro avg)  0.2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 15:38:20,685 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 15:38:20,687 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 15:42:52,003 epoch 4 - iter 53/538 - loss 0.12247425 - samples/sec: 0.82 - lr: 0.000038\n",
      "2022-08-08 15:52:22,218 epoch 4 - iter 159/538 - loss 0.12428103 - samples/sec: 0.79 - lr: 0.000037\n",
      "2022-08-08 15:56:55,569 epoch 4 - iter 212/538 - loss 0.12373928 - samples/sec: 0.82 - lr: 0.000037\n",
      "2022-08-08 16:01:42,759 epoch 4 - iter 265/538 - loss 0.12307052 - samples/sec: 0.80 - lr: 0.000036\n",
      "2022-08-08 16:06:26,984 epoch 4 - iter 318/538 - loss 0.12277810 - samples/sec: 0.80 - lr: 0.000036\n",
      "2022-08-08 16:10:55,094 epoch 4 - iter 371/538 - loss 0.12215008 - samples/sec: 0.83 - lr: 0.000035\n",
      "2022-08-08 16:15:42,341 epoch 4 - iter 424/538 - loss 0.12142270 - samples/sec: 0.80 - lr: 0.000035\n",
      "2022-08-08 16:20:20,368 epoch 4 - iter 477/538 - loss 0.12135792 - samples/sec: 0.81 - lr: 0.000034\n",
      "2022-08-08 16:25:07,805 epoch 4 - iter 530/538 - loss 0.12060096 - samples/sec: 0.80 - lr: 0.000033\n",
      "2022-08-08 16:25:49,641 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 16:25:49,642 EPOCH 4 done: loss 0.1208 - lr 0.000033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:17<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 16:29:07,518 Evaluating as a multi-label problem: True\n",
      "2022-08-08 16:29:07,549 DEV : loss 0.11556477099657059 - f1-score (micro avg)  0.2572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 16:29:34,086 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 16:29:34,088 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 16:34:16,519 epoch 5 - iter 53/538 - loss 0.11614203 - samples/sec: 0.80 - lr: 0.000033\n",
      "2022-08-08 16:39:04,738 epoch 5 - iter 106/538 - loss 0.11806596 - samples/sec: 0.82 - lr: 0.000032\n",
      "2022-08-08 16:43:58,195 epoch 5 - iter 159/538 - loss 0.11687277 - samples/sec: 0.78 - lr: 0.000032\n",
      "2022-08-08 16:48:52,798 epoch 5 - iter 212/538 - loss 0.11760355 - samples/sec: 0.78 - lr: 0.000031\n",
      "2022-08-08 16:53:26,074 epoch 5 - iter 265/538 - loss 0.11815117 - samples/sec: 0.80 - lr: 0.000031\n",
      "2022-08-08 16:58:01,490 epoch 5 - iter 318/538 - loss 0.11819542 - samples/sec: 0.80 - lr: 0.000030\n",
      "2022-08-08 17:02:49,826 epoch 5 - iter 371/538 - loss 0.12025258 - samples/sec: 0.79 - lr: 0.000030\n",
      "2022-08-08 17:07:16,614 epoch 5 - iter 424/538 - loss 0.12016816 - samples/sec: 0.84 - lr: 0.000029\n",
      "2022-08-08 17:11:43,622 epoch 5 - iter 477/538 - loss 0.11978848 - samples/sec: 0.84 - lr: 0.000028\n",
      "2022-08-08 17:16:23,606 epoch 5 - iter 530/538 - loss 0.11977650 - samples/sec: 0.82 - lr: 0.000028\n",
      "2022-08-08 17:17:04,764 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 17:17:04,765 EPOCH 5 done: loss 0.1199 - lr 0.000028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:17<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 17:20:22,257 Evaluating as a multi-label problem: True\n",
      "2022-08-08 17:20:22,285 DEV : loss 0.1146770715713501 - f1-score (micro avg)  0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 17:20:51,708 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 17:20:51,711 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 17:25:52,312 epoch 6 - iter 53/538 - loss 0.12655026 - samples/sec: 0.79 - lr: 0.000027\n",
      "2022-08-08 17:30:29,592 epoch 6 - iter 106/538 - loss 0.12056622 - samples/sec: 0.80 - lr: 0.000027\n",
      "2022-08-08 17:35:20,209 epoch 6 - iter 159/538 - loss 0.12021885 - samples/sec: 0.78 - lr: 0.000026\n",
      "2022-08-08 17:40:05,446 epoch 6 - iter 212/538 - loss 0.11899537 - samples/sec: 0.81 - lr: 0.000026\n",
      "2022-08-08 17:44:37,870 epoch 6 - iter 265/538 - loss 0.11862159 - samples/sec: 0.83 - lr: 0.000025\n",
      "2022-08-08 17:49:11,760 epoch 6 - iter 318/538 - loss 0.11763756 - samples/sec: 0.81 - lr: 0.000025\n",
      "2022-08-08 17:53:40,507 epoch 6 - iter 371/538 - loss 0.11682626 - samples/sec: 0.83 - lr: 0.000024\n",
      "2022-08-08 17:58:17,113 epoch 6 - iter 424/538 - loss 0.11735762 - samples/sec: 0.80 - lr: 0.000023\n",
      "2022-08-08 18:02:56,184 epoch 6 - iter 477/538 - loss 0.11726547 - samples/sec: 0.80 - lr: 0.000023\n",
      "2022-08-08 18:07:55,770 epoch 6 - iter 530/538 - loss 0.11727824 - samples/sec: 0.78 - lr: 0.000022\n",
      "2022-08-08 18:08:36,380 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 18:08:36,381 EPOCH 6 done: loss 0.1171 - lr 0.000022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:14<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 18:11:51,040 Evaluating as a multi-label problem: True\n",
      "2022-08-08 18:11:51,070 DEV : loss 0.11378749459981918 - f1-score (micro avg)  0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 18:12:21,112 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 18:12:21,114 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 18:17:08,083 epoch 7 - iter 53/538 - loss 0.10924838 - samples/sec: 0.79 - lr: 0.000022\n",
      "2022-08-08 18:22:12,794 epoch 7 - iter 106/538 - loss 0.11140955 - samples/sec: 0.77 - lr: 0.000021\n",
      "2022-08-08 18:26:56,999 epoch 7 - iter 159/538 - loss 0.11134250 - samples/sec: 0.79 - lr: 0.000021\n",
      "2022-08-08 18:31:37,927 epoch 7 - iter 212/538 - loss 0.11207300 - samples/sec: 0.80 - lr: 0.000020\n",
      "2022-08-08 18:36:35,787 epoch 7 - iter 265/538 - loss 0.11325684 - samples/sec: 0.78 - lr: 0.000020\n",
      "2022-08-08 18:41:09,031 epoch 7 - iter 318/538 - loss 0.11390611 - samples/sec: 0.81 - lr: 0.000019\n",
      "2022-08-08 18:45:47,168 epoch 7 - iter 371/538 - loss 0.11352278 - samples/sec: 0.81 - lr: 0.000018\n",
      "2022-08-08 18:50:31,248 epoch 7 - iter 424/538 - loss 0.11372048 - samples/sec: 0.81 - lr: 0.000018\n",
      "2022-08-08 18:55:07,166 epoch 7 - iter 477/538 - loss 0.11350532 - samples/sec: 0.80 - lr: 0.000017\n",
      "2022-08-08 19:00:39,935 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 19:00:39,936 EPOCH 7 done: loss 0.1132 - lr 0.000017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:15<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 19:03:55,886 Evaluating as a multi-label problem: True\n",
      "2022-08-08 19:03:55,914 DEV : loss 0.11650747060775757 - f1-score (micro avg)  0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 19:04:25,746 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 19:04:25,748 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 19:09:18,365 epoch 8 - iter 53/538 - loss 0.10604528 - samples/sec: 0.78 - lr: 0.000016\n",
      "2022-08-08 19:14:13,324 epoch 8 - iter 106/538 - loss 0.10449482 - samples/sec: 0.79 - lr: 0.000016\n",
      "2022-08-08 19:18:43,956 epoch 8 - iter 159/538 - loss 0.10674835 - samples/sec: 0.82 - lr: 0.000015\n",
      "2022-08-08 19:23:34,266 epoch 8 - iter 212/538 - loss 0.10681137 - samples/sec: 0.79 - lr: 0.000015\n",
      "2022-08-08 19:28:12,051 epoch 8 - iter 265/538 - loss 0.10820828 - samples/sec: 0.80 - lr: 0.000014\n",
      "2022-08-08 19:33:02,175 epoch 8 - iter 318/538 - loss 0.10925657 - samples/sec: 0.78 - lr: 0.000013\n",
      "2022-08-08 19:37:58,673 epoch 8 - iter 371/538 - loss 0.10915921 - samples/sec: 0.78 - lr: 0.000013\n",
      "2022-08-08 19:42:44,183 epoch 8 - iter 424/538 - loss 0.10925692 - samples/sec: 0.79 - lr: 0.000012\n",
      "2022-08-08 19:47:20,363 epoch 8 - iter 477/538 - loss 0.10911730 - samples/sec: 0.81 - lr: 0.000012\n",
      "2022-08-08 19:51:45,560 epoch 8 - iter 530/538 - loss 0.10866026 - samples/sec: 0.84 - lr: 0.000011\n",
      "2022-08-08 19:52:30,584 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 19:52:30,585 EPOCH 8 done: loss 0.1085 - lr 0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:16<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 19:55:47,607 Evaluating as a multi-label problem: True\n",
      "2022-08-08 19:55:47,638 DEV : loss 0.12065999954938889 - f1-score (micro avg)  0.2827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 19:56:17,432 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 19:56:17,434 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 20:01:00,186 epoch 9 - iter 53/538 - loss 0.10055127 - samples/sec: 0.79 - lr: 0.000011\n",
      "2022-08-08 20:05:30,682 epoch 9 - iter 106/538 - loss 0.10172580 - samples/sec: 0.82 - lr: 0.000010\n",
      "2022-08-08 20:10:09,935 epoch 9 - iter 159/538 - loss 0.10313713 - samples/sec: 0.80 - lr: 0.000010\n",
      "2022-08-08 20:14:45,431 epoch 9 - iter 212/538 - loss 0.10173206 - samples/sec: 0.80 - lr: 0.000009\n",
      "2022-08-08 20:24:35,978 epoch 9 - iter 318/538 - loss 0.10253791 - samples/sec: 0.79 - lr: 0.000008\n",
      "2022-08-08 20:29:33,577 epoch 9 - iter 371/538 - loss 0.10331777 - samples/sec: 0.78 - lr: 0.000007\n",
      "2022-08-08 20:34:19,253 epoch 9 - iter 424/538 - loss 0.10305409 - samples/sec: 0.80 - lr: 0.000007\n",
      "2022-08-08 20:38:59,203 epoch 9 - iter 477/538 - loss 0.10284194 - samples/sec: 0.79 - lr: 0.000006\n",
      "2022-08-08 20:43:43,853 epoch 9 - iter 530/538 - loss 0.10290826 - samples/sec: 0.79 - lr: 0.000006\n",
      "2022-08-08 20:44:26,737 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 20:44:26,738 EPOCH 9 done: loss 0.1029 - lr 0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:16<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 20:47:43,837 Evaluating as a multi-label problem: True\n",
      "2022-08-08 20:47:43,865 DEV : loss 0.12265961617231369 - f1-score (micro avg)  0.2184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 20:48:13,153 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 20:48:13,155 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 20:53:09,519 epoch 10 - iter 53/538 - loss 0.09854894 - samples/sec: 0.78 - lr: 0.000005\n",
      "2022-08-08 20:57:53,385 epoch 10 - iter 106/538 - loss 0.09859455 - samples/sec: 0.79 - lr: 0.000005\n",
      "2022-08-08 21:02:48,583 epoch 10 - iter 159/538 - loss 0.09931621 - samples/sec: 0.78 - lr: 0.000004\n",
      "2022-08-08 21:07:31,199 epoch 10 - iter 212/538 - loss 0.09784902 - samples/sec: 0.79 - lr: 0.000003\n",
      "2022-08-08 21:12:01,831 epoch 10 - iter 265/538 - loss 0.09854039 - samples/sec: 0.82 - lr: 0.000003\n",
      "2022-08-08 21:16:35,773 epoch 10 - iter 318/538 - loss 0.09751575 - samples/sec: 0.80 - lr: 0.000002\n",
      "2022-08-08 21:21:14,801 epoch 10 - iter 371/538 - loss 0.09719522 - samples/sec: 0.82 - lr: 0.000002\n",
      "2022-08-08 21:25:55,647 epoch 10 - iter 424/538 - loss 0.09749459 - samples/sec: 0.81 - lr: 0.000001\n",
      "2022-08-08 21:30:30,920 epoch 10 - iter 477/538 - loss 0.09769161 - samples/sec: 0.81 - lr: 0.000001\n",
      "2022-08-08 21:35:36,603 epoch 10 - iter 530/538 - loss 0.09709624 - samples/sec: 0.77 - lr: 0.000000\n",
      "2022-08-08 21:36:21,318 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 21:36:21,319 EPOCH 10 done: loss 0.0972 - lr 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:31<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 21:39:53,246 Evaluating as a multi-label problem: True\n",
      "2022-08-08 21:39:53,278 DEV : loss 0.12752346694469452 - f1-score (micro avg)  0.2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 21:40:20,771 BAD EPOCHS (no improvement): 4\n",
      "2022-08-08 21:40:23,067 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-08 21:40:23,069 Testing using last state of model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 111/111 [03:30<00:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 21:43:54,075 Evaluating as a multi-label problem: True\n",
      "2022-08-08 21:43:54,133 0.4136\t0.1938\t0.2639\t0.0249\n",
      "2022-08-08 21:43:54,136 \n",
      "Results:\n",
      "- F-score (micro) 0.2639\n",
      "- F-score (macro) 0.1547\n",
      "- Accuracy 0.0249\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      TA0005     0.4612    0.5000    0.4798       214\n",
      "      TA0003     0.5072    0.1955    0.2823       179\n",
      "      TA0002     0.3871    0.2707    0.3186       133\n",
      "      TA0011     0.3247    0.2381    0.2747       105\n",
      "      TA0004     0.3429    0.0992    0.1538       121\n",
      "      TA0007     0.3617    0.1683    0.2297       101\n",
      "      TA0008     0.0000    0.0000    0.0000       103\n",
      "      TA0006     0.0000    0.0000    0.0000        89\n",
      "      TA0009     0.2500    0.0769    0.1176        65\n",
      "      TA0001     0.0000    0.0000    0.0000        63\n",
      "      TA0010     0.0000    0.0000    0.0000        30\n",
      "      TA0040     0.0000    0.0000    0.0000        20\n",
      "\n",
      "   micro avg     0.4136    0.1938    0.2639      1223\n",
      "   macro avg     0.2196    0.1291    0.1547      1223\n",
      "weighted avg     0.3020    0.1938    0.2239      1223\n",
      " samples avg     0.2042    0.1731    0.1532      1223\n",
      "\n",
      "2022-08-08 21:43:54,138 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.26391982182628065,\n",
       " 'dev_score_history': [0.4263602251407129,\n",
       "  0.25721153846153844,\n",
       "  0.2614227877385772,\n",
       "  0.25721153846153844,\n",
       "  0.1972972972972973,\n",
       "  0.32098765432098764,\n",
       "  0.27695934001178546,\n",
       "  0.2827102803738318,\n",
       "  0.21839080459770116,\n",
       "  0.26391982182628065],\n",
       " 'train_loss_history': [0.12502859800458507,\n",
       "  0.12522849195453314,\n",
       "  0.12216347816043627,\n",
       "  0.1207552849692483,\n",
       "  0.1198530072436346,\n",
       "  0.11712505180928787,\n",
       "  0.11323935868820958,\n",
       "  0.10854621327804145,\n",
       "  0.10285568569672596,\n",
       "  0.09724806033794986],\n",
       " 'dev_loss_history': [0.17610898613929749,\n",
       "  0.11544405668973923,\n",
       "  0.11832620203495026,\n",
       "  0.11556477099657059,\n",
       "  0.1146770715713501,\n",
       "  0.11378749459981918,\n",
       "  0.11650747060775757,\n",
       "  0.12065999954938889,\n",
       "  0.12265961617231369,\n",
       "  0.12752346694469452]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize transformer document embeddings (many models are available)\n",
    "document_embeddings = TransformerDocumentEmbeddings('binay1999/text_classification_cybertexts', fine_tune=True)\n",
    "\n",
    "# create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type=label_type, multi_label=True)\n",
    "\n",
    "# initialize trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# run training with fine-tuning\n",
    "trainer.fine_tune('test_model',\n",
    "                  learning_rate=5.0e-5,\n",
    "                  mini_batch_size=4,\n",
    "                  max_epochs=10,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d7053",
   "metadata": {},
   "source": [
    "## LSTM (with word2vec):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729114e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m WordEmbeddings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m document_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mDocumentRNNEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/flair/embeddings/document.py:268\u001b[0m, in \u001b[0;36mDocumentRNNEmbeddings.__init__\u001b[0;34m(self, embeddings, hidden_size, rnn_layers, reproject_words, reproject_words_dimension, bidirectional, dropout, word_dropout, locked_dropout, rnn_type, fine_tune)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_dropout \u001b[38;5;241m=\u001b[39m WordDropout(word_dropout) \u001b[38;5;28;01mif\u001b[39;00m word_dropout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    266\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_uniform_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_reprojection_map\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/flair/embeddings/document.py:378\u001b[0m, in \u001b[0;36mDocumentRNNEmbeddings._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m             _flat_weights_names\u001b[38;5;241m.\u001b[39mextend(param_names)\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(child_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_flat_weights_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, _flat_weights_names)\n\u001b[0;32m--> 378\u001b[0m \u001b[43mchild_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:189\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28;01mlambda\u001b[39;00m wn: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)(wn) \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Flattens params (on CUDA)\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:175\u001b[0m, in \u001b[0;36mRNNBase.flatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    174\u001b[0m     num_weights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 175\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cudnn_rnn_flatten_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cudnn_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "embedding = WordEmbeddings('en')\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings([embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type=label_type, multi_label=True)\n",
    "\n",
    "# initialize trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# run training with fine-tuning\n",
    "trainer.fine_tune('test_model_word2vec',\n",
    "                  learning_rate=5.0e-5,\n",
    "                  mini_batch_size=4,\n",
    "                  max_epochs=10,\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
