{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "\n",
    "\n",
    "import spacy\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf12c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e30c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53de720",
   "metadata": {},
   "source": [
    "# Opening Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a66595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle: \n",
    "\n",
    "#with open('merged_data_no_duplicates.pickle', 'rb') as handle:\n",
    "#    (X_train_text, X_test_text, _, _, Y_train, Y_test) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e386da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle lemmatised: \n",
    "\n",
    "with open('merged_data_lemma.pickle', 'rb') as handle:\n",
    "    (X_train_text, X_test_text, _, _, Y_train, Y_test) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc50fc",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f298d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# call methods for feature extraction and evaluation:\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from methods import feature_extraction, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = feature_extraction('CountVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4993dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = feature_extraction('TfIdfVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = feature_extraction('glove-wiki-gigaword-100', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d505d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = feature_extraction('glove-wiki-gigaword-100', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b869ed",
   "metadata": {},
   "source": [
    "# Classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939eada",
   "metadata": {},
   "source": [
    "## Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182639ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "naive_bayes_classifier = OneVsRestClassifier(MultinomialNB())\n",
    "naive_bayes_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pd.DataFrame(naive_bayes_classifier.predict_proba(X_test), columns = Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_proba > 0.005).astype(int) # if increase threshold, recall decreases and precision (could) increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc1007",
   "metadata": {},
   "source": [
    "## SVC: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test: First delete techniques less than 9 \n",
    "# We fix the random state to have the same dataset in our different tests@\n",
    "\n",
    "sv_classifier = OneVsRestClassifier(LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 1000, class_weight = 'balanced', random_state=42), n_jobs = 1)\n",
    "sv_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(sv_classifier.predict(X_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65275cc4",
   "metadata": {},
   "source": [
    "## Calibrated Classifier for SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a641af",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CalibratedClassifierCV(sv_classifier) \n",
    "multioutput_clf = MultiOutputClassifier(clf).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatnonzero(Y_pred.sum(axis=1) == 0) # index of all reports without predictions@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fbf360",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.flatnonzero(Y_pred.sum(axis=1) == 0))/len(Y_test) # 27% of reports are never predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1902d",
   "metadata": {},
   "source": [
    "## Multi-label kNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f732fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = MLkNN(k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "knn.fit(X_train.values, Y_train.values)\n",
    "\n",
    "# predict\n",
    "predictions = knn.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d408c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_score(Y_test, predictions, beta=0.5, average ='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fcc7e",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26619667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimension using pca: \n",
    "\n",
    "pca = PCA(n_components=150)\n",
    "pca.fit(X_train)\n",
    "pca_result = pca.transform(X_train)\n",
    "x_test_result = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = OneVsRestClassifier(LogisticRegression(random_state=0, multi_class='multinomial', solver='lbfgs', max_iter = 1000)).fit(X_train, Y_train)\n",
    "\n",
    "predictions = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f886f86",
   "metadata": {},
   "source": [
    "## DT AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92517b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_adaboost = OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=0)).fit(X_train, Y_train)\n",
    "predictions_ada = dt_adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc8cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions_ada, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72c0ee",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluation(predictions_rf, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e0a10",
   "metadata": {},
   "source": [
    "# Classifier Chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_model(model):\n",
    "    model_chain = ClassifierChain(model, order='random', random_state=0)\n",
    "    return model_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17177095",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chain_model(log_reg) # change model appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686314be",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainModel = chain.fit(X_train.values, Y_train.values)\n",
    "predictions = chainModel.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ff8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f2099",
   "metadata": {},
   "source": [
    "# Neural Networks: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2026d4a",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d616902",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=1, max_iter=300).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478368f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions_mlp, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c4654",
   "metadata": {},
   "source": [
    "## Loading data from flair: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fasttext_format_test.txt', 'w') as file:\n",
    "    for i in range(len(Y_test)):\n",
    "        file.write(' '.join(['__label__'+col for col in Y_test.columns if Y_test.iloc[i][col] == 1]) + ' ' + X_test_text.iloc[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "flair.device = 'cpu'\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '.'\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus = ClassificationCorpus(data_folder,\n",
    "                                      test_file='fasttext_format_test.txt',\n",
    "                                      dev_file='fasttext_format_test.txt',\n",
    "                                      train_file='fasttext_format_train.txt',\n",
    "                                      label_type='tactic',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c819a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what label do we want to predict?\n",
    "label_type = 'tactic'\n",
    "\n",
    "# 3. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710d69b",
   "metadata": {},
   "source": [
    "## Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize transformer document embeddings (many models are available)\n",
    "document_embeddings = TransformerDocumentEmbeddings('binay1999/text_classification_cybertexts', fine_tune=True)\n",
    "\n",
    "# create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type=label_type, multi_label=True)\n",
    "\n",
    "# initialize trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# run training with fine-tuning\n",
    "trainer.fine_tune('test_model',\n",
    "                  learning_rate=5.0e-5,\n",
    "                  mini_batch_size=4,\n",
    "                  max_epochs=10,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d8afa",
   "metadata": {},
   "source": [
    "## LSTM (with word2Vec):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dddb7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding = WordEmbeddings('en')\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings([embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type=label_type, multi_label=True)\n",
    "\n",
    "# initialize trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# run training with fine-tuning\n",
    "trainer.fine_tune('test_model_word2vec',\n",
    "                  learning_rate=5.0e-5,\n",
    "                  mini_batch_size=4,\n",
    "                  max_epochs=10,\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
