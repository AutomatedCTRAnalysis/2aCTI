{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "     \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "import pickle \n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "from plotly.subplots import make_subplots\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "import flair\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf12c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e30c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53de720",
   "metadata": {},
   "source": [
    "# Opening Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a66595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle witout lemmatisation: \n",
    "\n",
    "with open('merged_data_no_duplicates.pickle', 'rb') as handle:\n",
    "    (X_train_text, X_test_text, _, _, Y_train, Y_test) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc50fc",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f298d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call methods for feature extraction and evaluation:\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from methods import feature_extraction, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034f0a1",
   "metadata": {},
   "source": [
    "## Count Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = feature_extraction('CountVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9c110",
   "metadata": {},
   "source": [
    "## TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4993dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = feature_extraction('TfIdfVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed00f2",
   "metadata": {},
   "source": [
    "## Glove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d506cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "glv = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = feature_extraction('glove-wiki-gigaword-100', X_train_text, X_test_text, embedding_type = glv, weighted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c7f04",
   "metadata": {},
   "source": [
    "## Pre-trained word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_google = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = feature_extraction('embedding', X_train_text, X_test_text, embedding_type = w2v_google, weighted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edca74",
   "metadata": {},
   "source": [
    "## Trained word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2930a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load(\"word2vec.model\").wv\n",
    "x_train, X_test = feature_extraction(\"embedding\", X_train_text, X_test_text, embedding_type = w2v, weighted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4078f",
   "metadata": {},
   "source": [
    "## Trained doc2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90cf21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec = Doc2Vec.load(\"doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = feature_extraction(\"embedding\", X_train_text, X_test_text, embedding_type = doc2vec, weighted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b869ed",
   "metadata": {},
   "source": [
    "# Linear Classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939eada",
   "metadata": {},
   "source": [
    "## Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182639ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = OneVsRestClassifier(MultinomialNB(alpha = 0))\n",
    "naive_bayes_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pd.DataFrame(naive_bayes_classifier.predict_proba(X_test), columns = Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_proba > 0.005).astype(int) # if increase threshold, recall decreases and precision (could) increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc1007",
   "metadata": {},
   "source": [
    "## SVC: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test: First delete techniques less than 9 \n",
    "# We fix the random state to have the same dataset in our different tests@\n",
    "\n",
    "sv_classifier = OneVsRestClassifier(LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 500, class_weight = 'balanced', random_state=42), n_jobs = -1)\n",
    "sv_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(sv_classifier.predict(X_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle (with less features): \n",
    "\n",
    "with open('/homes/lgf21/API/app/technique_MINSV.pickle', 'wb') as handle:\n",
    "    pickle.dump((sv_classifier), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fcc7e",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26619667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimension using pca: \n",
    "\n",
    "pca = PCA(n_components=75)\n",
    "pca.fit(X_train)\n",
    "pca_result = pca.transform(X_train)\n",
    "x_test_result = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = OneVsRestClassifier(LogisticRegression(random_state=0, multi_class='multinomial', solver='lbfgs', max_iter = 500)).fit(X_train, Y_train)\n",
    "predictions = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb9718",
   "metadata": {},
   "source": [
    "# Non-Linear Classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c72f54",
   "metadata": {},
   "source": [
    "## Decision Tree: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0dff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = OneVsRestClassifier(DecisionTreeClassifier(random_state=0))\n",
    "dt.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9760f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(dt.predict(X_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701436d",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d640e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=20, random_state=0, class_weight='balanced') # change max depth - (higher the larger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6088b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef546434",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1902d",
   "metadata": {},
   "source": [
    "## Multi-label kNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d408c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_score(Y_test, predictions, beta=0.5, average ='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333e1ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f886f86",
   "metadata": {},
   "source": [
    "## DT AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92517b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_adaboost = OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=0)).fit(X_train, Y_train)\n",
    "predictions_ada = dt_adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc8cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions_ada, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e0a10",
   "metadata": {},
   "source": [
    "# Classifier Chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_model(model):\n",
    "    model_chain = ClassifierChain(model, order='random', random_state=0)\n",
    "    return model_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17177095",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chain_model(dt) # change model appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686314be",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainModel = chain.fit(X_train, Y_train)\n",
    "predictions = chainModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ff8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f2099",
   "metadata": {},
   "source": [
    "# Neural Networks: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2026d4a",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d616902",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=1, max_iter=300, hidden_layer_sizes = []).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478368f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(predictions_mlp, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c4654",
   "metadata": {},
   "source": [
    "## Loading data from flair: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fasttext_format_test.txt', 'w') as file:\n",
    "    for i in range(len(Y_test)):\n",
    "        file.write(' '.join(['__label__'+col for col in Y_test.columns if Y_test.iloc[i][col] == 1]) + ' ' + X_test_text.iloc[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "flair.device = 'cpu'\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '.'\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus = ClassificationCorpus(data_folder,\n",
    "                                      test_file='fasttext_format_test.txt',\n",
    "                                      dev_file='fasttext_format_test.txt',\n",
    "                                      train_file='fasttext_format_train.txt',\n",
    "                                      label_type='tactic',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c819a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to be predicted:\n",
    "label_type = 'technique'\n",
    "# label dictionary\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710d69b",
   "metadata": {},
   "source": [
    "## Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize transformer document embeddings (many models are available)\n",
    "document_embeddings = TransformerDocumentEmbeddings('binay1999/text_classification_cybertexts', fine_tune=True)\n",
    "\n",
    "# create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type=label_type, multi_label=True)\n",
    "\n",
    "# initialize trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# run training with fine-tuning\n",
    "trainer.fine_tune('test_model',\n",
    "                  learning_rate=5.0e-4,\n",
    "                  mini_batch_size=64,\n",
    "                  max_epochs=5,\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
