{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1180c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "\n",
    "\n",
    "import spacy\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e967a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /homes/lgf21/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9b5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle without lemmatisation: \n",
    "\n",
    "with open('merged_data_no_duplicates.pickle', 'rb') as handle:\n",
    "    (X_train_text, X_test_text, Y_train_tactic, Y_test_tactic, Y_train, Y_test) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ed77f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Exploit Public-Facing Application - Enterprise...\n",
       "1       Emergency Incident ResponseReport a Confirmed ...\n",
       "2       Pass the Hash - Enterprise | MITRE ATT&CK\\xe2\\...\n",
       "3       Extra Window Memory Injection - Enterprise | M...\n",
       "4       Tropic Trooper Targets Taiwanese Government an...\n",
       "                              ...                        \n",
       "2142     Molerats Delivers  MALWARE_NAME  Backdoor to ...\n",
       "2143     Transparent Tribe  Evolution analysis  part  ...\n",
       "2144     WWW FIDELISSECURITY COM  Fidelis Cybersecurit...\n",
       "2145     OilRig uses  MALWARE_NAME  IIS Backdoor on Ta...\n",
       "2146     The OilRig Campaign  Attacks on Saudi Arabian...\n",
       "Name: Text, Length: 2072, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea3f71",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "978b47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call methods for feature extraction and evaluation:\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from methods import feature_extraction, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc44a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = feature_extraction('TfIdfVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2cd7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(class_weight='balanced', dual=False,\n",
       "                                        random_state=42),\n",
       "                    n_jobs=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test: First delete techniques less than 9 \n",
    "# We fix the random state to have the same dataset in our different tests@\n",
    "\n",
    "sv_classifier = OneVsRestClassifier(LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 1000, class_weight = 'balanced', random_state=42), n_jobs = 1)\n",
    "sv_classifier.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37484b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(sv_classifier.predict(X_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle technique performance: \n",
    "\n",
    "#with open('postprocessing.pickle', 'wb') as handle:\n",
    " #   pickle.dump(sv_classifier, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e04ab2",
   "metadata": {},
   "source": [
    "# Open Tactic Performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22854a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle: \n",
    "\n",
    "with open('tactic_MLP_TFIDF_model.pickle', 'rb') as handle:\n",
    "    tactic_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5beeb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../src/scraping/scraped_data/tactic_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "350b6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data) as file:\n",
    "    tactic_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16dc519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred_tactic = pd.DataFrame(tactic_model.predict(X_test), columns = Y_test_tactic.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9ca5d",
   "metadata": {},
   "source": [
    "# Hanging Node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7221bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tactics and list of techniques:\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe37230",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MLPClassifier' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tactic_prob \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtactic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mY_test_tactic\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MLPClassifier' object is not callable"
     ]
    }
   ],
   "source": [
    "tactic_prob = pd.DataFrame(tactic_model(X_test), columns=Y_test_tactic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8272a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if scaling at (-1,1) then threshold of .5 \n",
    "# scaling determines improvement \n",
    "# (0-1) performs poorly with threshold of .5 \n",
    "\n",
    "technique_prob = pd.DataFrame(MinMaxScaler((-1, 1)).fit_transform(sv_classifier.decision_function(X_test)), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c512995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hanging_node(i, tactic_proba, technique_proba,tactic_threshold=0.5, technique_threshold=0.5, a = 1,b = 0, c=1, d=0):\n",
    "    assert a > technique_threshold and c > technique_threshold and b < tactic_threshold and d < tactic_threshold\n",
    "    pred_tactics = [tactic for tactic in tactic_proba.columns if tactic_proba.iloc[i][tactic] > tactic_threshold]\n",
    "    pred_techniques = [technique for technique in technique_proba.columns if technique_proba.iloc[i][technique] > technique_threshold]\n",
    "    #return pred_tactics, pred_techniques\n",
    "    print((pred_tactics, pred_techniques))\n",
    "    for tactic in tactic_proba.columns:\n",
    "        for technique in tactic_data[tactic]['Technique_ID'][0]:\n",
    "            if technique in pred_techniques and tactic not in pred_tactics:\n",
    "                if technique_proba.iloc[i][technique] > a and tactic_proba.iloc[i][tactic] > b:\n",
    "                    pred_tactics.append(tactic)\n",
    "                elif technique_proba.iloc[i][technique] < c and tactic_proba.iloc[i][tactic] < d:\n",
    "                    pred_techniques.remove(technique)\n",
    "    print(pred_tactics, pred_techniques)\n",
    "    print('-----------------------------')\n",
    "    return pred_tactics, pred_techniques\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1872a1e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tactic_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m Y_test_techniques_hanging_node \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test)):\n\u001b[0;32m----> 4\u001b[0m     pred_tactics, pred_techniques \u001b[38;5;241m=\u001b[39m hanging_node(i, \u001b[43mtactic_prob\u001b[49m, technique_prob,tactic_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, technique_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,  a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.55\u001b[39m, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.9\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.95\u001b[39m, d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.30\u001b[39m)\n\u001b[1;32m      5\u001b[0m     Y_test_tactics_hanging_node\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tactic \u001b[38;5;129;01min\u001b[39;00m pred_tactics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tactic \u001b[38;5;129;01min\u001b[39;00m Y_test_tactic\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[1;32m      6\u001b[0m     Y_test_techniques_hanging_node\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m technique \u001b[38;5;129;01min\u001b[39;00m pred_techniques \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m technique \u001b[38;5;129;01min\u001b[39;00m Y_test\u001b[38;5;241m.\u001b[39mcolumns])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tactic_prob' is not defined"
     ]
    }
   ],
   "source": [
    "Y_test_tactics_hanging_node = []\n",
    "Y_test_techniques_hanging_node = []\n",
    "for i in range(len(X_test)):\n",
    "    pred_tactics, pred_techniques = hanging_node(i, tactic_prob, technique_prob,tactic_threshold=0, technique_threshold=0.5,  a = 0.55, b = -0.9, c = 0.95, d = -0.30)\n",
    "    Y_test_tactics_hanging_node.append([1 if tactic in pred_tactics else 0 for tactic in Y_test_tactic.columns])\n",
    "    Y_test_techniques_hanging_node.append([1 if technique in pred_techniques else 0 for technique in Y_test.columns])\n",
    "\n",
    "Y_test_tactics_hanging_node = pd.DataFrame(Y_test_tactics_hanging_node, columns=Y_test_tactic.columns)\n",
    "Y_test_techniques_hanging_node = pd.DataFrame(Y_test_techniques_hanging_node, columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222128c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_test_tactics_hanging_node, Y_test_tactic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_test_techniques_hanging_node, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979199a0",
   "metadata": {},
   "source": [
    "# Train Model on Reports Tactics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if training on only techniques improves or not\n",
    "# only train techniques on reports belonging to a techniques' tactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key as technique, value as tactic.\n",
    "\n",
    "from collections import defaultdict\n",
    "tactic_to_technique = defaultdict(list)\n",
    "for tactic in tactic_data:\n",
    "    for technique in tactic_data[tactic]['Technique_ID'][0]:\n",
    "        if tactic in Y_train_tactic.columns:\n",
    "            tactic_to_technique[technique].append(tactic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62517cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.concat([Y_train, Y_test]).reset_index(drop=True)\n",
    "Y_tactic = pd.concat([Y_train_tactic, Y_test_tactic]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28caf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for matching between tactic and technique\n",
    "# find technique that are not in dictionary. \n",
    "# for Y_r, find report that only contains that technique and find what tactics is has \n",
    "\n",
    "for technique in Y.columns:\n",
    "    if technique not in tactic_to_technique:\n",
    "        index = Y[(Y.sum(axis=1)==1) & (Y[technique] == 1)].index[-1]\n",
    "        tactics = [tactic for tactic in Y_tactic.columns if \n",
    "                       int(Y_tactic.loc[index, tactic])==1]\n",
    "        if len(tactics) == 0:\n",
    "            print(technique)\n",
    "            print(Y[(Y.sum(axis=1)==1) & (Y[technique] == 1)].index)\n",
    "        tactic_to_technique[technique] = tactics\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d50d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_tactic[Y_train_tactic.sum(axis=1)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text.iloc[977]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec00746",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reset_index(drop=True)\n",
    "Y_train_tactic = Y_train_tactic.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_tactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b90b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1def588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train[Y_train['T1108']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18519431",
   "metadata": {},
   "outputs": [],
   "source": [
    "tactic_to_technique[\"T1108\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "for technique in Y_train.columns:\n",
    "    indexes = Y_train_tactic[Y_train_tactic.apply(lambda x: any(x[tactic] ==1 for tactic in tactic_to_technique[technique]), axis=1)].index\n",
    "    X_train_technique = X_train.loc[indexes]\n",
    "    Y_train_technique = Y_train.loc[indexes, technique]\n",
    "    clf = LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 1000, class_weight = 'balanced', random_state=42)\n",
    "    clf.fit(X_train_technique, Y_train_technique)\n",
    "    classifiers.append(clf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa352cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(0, index=X_test.index, columns=Y_test.columns)\n",
    "for i, technique in enumerate(Y_test.columns):\n",
    "    indexes = Y_test_pred_tactic[Y_test_pred_tactic.apply(lambda x: any(x[tactic] ==1 for tactic in tactic_to_technique[technique]), axis=1)].index\n",
    "    Y_pred.loc[indexes, technique] = classifiers[i].predict(X_test.loc[indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_pred, Y_test) # performance for technique "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94fb88",
   "metadata": {},
   "source": [
    "# Linking Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08735f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../src/scraping/tactic_dataset.json'\n",
    "\n",
    "with open(data) as file:\n",
    "    tactic_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tactic = pd.DataFrame(tactic_data).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tactic['Technique_ID'] = df_tactic['Technique_ID'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a89bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tactic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tactic = df_tactic[['Tactic_ID', 'Technique_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ff94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# technique model\n",
    "# Open Pickle: \n",
    "\n",
    "with open('tactic_model.pickle', 'rb') as handle:\n",
    "    tactic_model = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
