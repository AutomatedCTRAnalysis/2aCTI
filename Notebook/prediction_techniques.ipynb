{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6d1180c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "\n",
    "\n",
    "import spacy\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2e9b5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcatt_data = '../src/rcatt_training_data_original.csv'\n",
    "scraped_data = '../src/training_dataset_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1282ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform into dataframes: \n",
    "\n",
    "df_r = pd.read_csv(rcatt_data).reset_index(drop = True)\n",
    "df_r = df_r[~df_r['Text'].duplicated()]\n",
    "df_s = pd.read_csv(scraped_data).reset_index(drop = True).rename(columns={'text': 'Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "27d6913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from string to list using literal_eval:\n",
    "\n",
    "for col in ['mitre_domain', 'tech_name', 'tech_id', 'tactic_id', 'software_id']:\n",
    "    df_s[col] = df_s[col].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6e7946cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "Y_s = mlb.fit_transform(df_s['tech_id'])\n",
    "Y_s = pd.DataFrame(Y_s, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "55562df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "Y_s_tactic = mlb.fit_transform(df_s['tactic_id'])\n",
    "Y_s_tactic = pd.DataFrame(Y_s_tactic, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb021c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = df_r['Text']\n",
    "Y_r = df_r[[col for col in df_r.columns if col.startswith('T') and col[1:].isdecimal()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0bb7e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_r_tactic = df_r[[col for col in df_r.columns if col.startswith('TA')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45acbeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_r = list(set(Y_s.columns).difference(set(Y_r.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9953e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_s = list(set(Y_r.columns).difference(set(Y_s.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa65e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = list(set(Y_s.columns).intersection(set(Y_r.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a477a5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n",
      "/tmp/ipykernel_264876/1701853409.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y1[r_s] = 0\n"
     ]
    }
   ],
   "source": [
    "Y1 = Y_s[rs]\n",
    "Y1[r_s] = 0\n",
    "Y_s = Y1[Y1.sum(axis=1)>0] \n",
    "X_s = df_s['Text']\n",
    "X_s = X_s[Y1.sum(axis=1)>0] # all urls who map at least one of the techniques in Y1\n",
    "Y_s_tactic = Y_s_tactic[Y1.sum(axis=1)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "75e47e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r_train, X_test_text, Y_r_train, Y_test, Y_r_train_tactic, Y_test_tactic = train_test_split(X_r, Y_r, Y_r_tactic, test_size=0.3,\n",
    "                                                    random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f980371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = pd.concat([X_r_train, X_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1147b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.concat([Y_r_train, Y_s]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6c13b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_tactic = pd.concat([Y_r_train_tactic, Y_s_tactic]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3575a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_tactic = Y_train_tactic.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "978b47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(featureExtract, X_train_text, X_test_text, average = False):\n",
    "    if featureExtract in ['CountVectorizer', 'TfIdfVectorizer']:\n",
    "        if featureExtract== 'CountVectorizer':\n",
    "            fe = CountVectorizer(analyzer ='word', stop_words ='english', lowercase = True, min_df = 2, max_df = 0.99) # if words used less than 0.001 % --> ignore  \n",
    "        else:\n",
    "            fe = TfidfVectorizer(analyzer = 'word', stop_words='english', lowercase=True, min_df = 2, max_df=0.99)\n",
    "        \n",
    "        X_train = fe.fit_transform(X_train_text)\n",
    "        X_train = pd.DataFrame(X_train.toarray(), columns = fe.get_feature_names()) \n",
    "        X_test = fe.transform(X_test_text)\n",
    "        X_test = pd.DataFrame(X_test.toarray(), columns = fe.get_feature_names())\n",
    "    \n",
    "    else:\n",
    "        model = gensim.downloader.load(featureExtract)\n",
    "        # sent is tokenised sentence on which we do the embedding\n",
    "        def get_embeddings(sent):\n",
    "            # if text not in vocab:\n",
    "            words_in_vocab = [word for word in sent if word in model]\n",
    "            if not words_in_vocab:\n",
    "                return np.zeros_like(model['the'])\n",
    "            emb = model[words_in_vocab]\n",
    "            return np.mean(emb, axis=0) if average else np.sum(emb, axis=0)\n",
    "        #perform tokenisation\n",
    "        X_train = pd.DataFrame(X_train_text.progress_apply(nltk.word_tokenize).progress_apply(get_embeddings).values.tolist())\n",
    "        X_test = pd.DataFrame(X_test_text.progress_apply(nltk.word_tokenize).progress_apply(get_embeddings).values.tolist())\n",
    "    return X_train, X_test\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc44a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = feature_extraction('TfIdfVectorizer', X_train_text, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "903ffee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2b00f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if articles have a cosine similarity of more than 90%\n",
    "duplicates = set() \n",
    "for i in range(similarities.shape[0]):\n",
    "    for j in range(similarities.shape[1]):\n",
    "        if similarities[i][j] > 0.9:\n",
    "            \n",
    "            duplicates.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b33ccaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove similar articles\n",
    "X_train_text = X_train_text[~X_train_text.index.isin(duplicates)]\n",
    "X_train = X_train[~X_train.index.isin(duplicates)]\n",
    "Y_train = Y_train[~Y_train.index.isin(duplicates)]\n",
    "Y_train_tactic = Y_train_tactic[~Y_train_tactic.index.isin(duplicates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4bb744fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Y_pred, Y_test):\n",
    "    macro_precision = precision_score(Y_test, Y_pred, average ='macro')\n",
    "    micro_precision = precision_score(Y_test, Y_pred, average ='micro')\n",
    "    macro_recall = recall_score(Y_test, Y_pred, average='macro')\n",
    "    micro_recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "    macro_fscore = fbeta_score(Y_test, Y_pred, beta=0.5, average ='macro')\n",
    "    micro_fscore = fbeta_score(Y_test, Y_pred, beta=0.5, average ='micro')\n",
    "    l_metric = ['macro precision', 'micro precision', 'macro recall', 'micro recall', 'macro fscore', 'micro fscore']\n",
    "    l_result = [macro_precision, micro_precision, macro_recall, micro_recall, macro_fscore, micro_fscore]\n",
    "    df_res = pd.DataFrame({'metric': l_metric, 'result': l_result})\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce2cd7e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [150]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train and test: First delete techniques less than 9 \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# We fix the random state to have the same dataset in our different tests@\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sv_classifier \u001b[38;5;241m=\u001b[39m OneVsRestClassifier(LinearSVC(penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_hinge\u001b[39m\u001b[38;5;124m'\u001b[39m, dual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43msv_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/multiclass.py:337\u001b[0m, in \u001b[0;36mOneVsRestClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    333\u001b[0m columns \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# In cases where individual estimators are very fast to train setting\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# of spawning threads.  See joblib issue #112.\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_binary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnot \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/multiclass.py:85\u001b[0m, in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m clone(estimator)\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py:257\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    254\u001b[0m check_classification_targets(y)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrammer_singer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1186\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1183\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1185\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[0;32m-> 1186\u001b[0m raw_coef_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mliblinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misspmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "File \u001b[0;32msklearn/svm/_liblinear.pyx:39\u001b[0m, in \u001b[0;36msklearn.svm._liblinear.train_wrap\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mcount_nonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/numpy/core/numeric.py:486\u001b[0m, in \u001b[0;36mcount_nonzero\u001b[0;34m(a, axis, keepdims)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03mCounts the number of non-zero values in the array ``a``.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m       [3]])\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keepdims:\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_nonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m a \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# TODO: this works around .astype(bool) not working properly (gh-9847)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and test: First delete techniques less than 9 \n",
    "# We fix the random state to have the same dataset in our different tests@\n",
    "\n",
    "sv_classifier = OneVsRestClassifier(LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 1000, class_weight = 'balanced', random_state=42), n_jobs = 1)\n",
    "sv_classifier.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37484b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(sv_classifier.predict(X_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e04ab2",
   "metadata": {},
   "source": [
    "# Open Tactic Performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22854a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle: \n",
    "\n",
    "with open('tactic_model.pickle', 'rb') as handle:\n",
    "    tactic_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beeb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../src/scraping/tactic_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data) as file:\n",
    "    tactic_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4403f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Pickle: \n",
    "\n",
    "with open('tactic_train_test.pickle', 'rb') as handle:\n",
    "    X_train_tactic_pickle, X_test_tactic_pickle, Y_train_tactic_pickle, Y_test_tactic_pickle = pickle.load(handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ade7488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA0006</th>\n",
       "      <th>TA0002</th>\n",
       "      <th>TA0040</th>\n",
       "      <th>TA0003</th>\n",
       "      <th>TA0004</th>\n",
       "      <th>TA0008</th>\n",
       "      <th>TA0005</th>\n",
       "      <th>TA0010</th>\n",
       "      <th>TA0007</th>\n",
       "      <th>TA0009</th>\n",
       "      <th>TA0011</th>\n",
       "      <th>TA0001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TA0006  TA0002  TA0040  TA0003  TA0004  TA0008  TA0005  TA0010  TA0007  \\\n",
       "319        0       0       0       0       0       0       1       0       0   \n",
       "336        0       0       1       0       0       0       0       0       0   \n",
       "1077       0       1       0       1       1       0       1       0       1   \n",
       "486        0       0       0       0       1       0       1       0       0   \n",
       "371        0       0       0       0       0       1       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1477       0       0       0       1       1       0       0       0       0   \n",
       "1376       0       1       0       1       1       0       0       0       0   \n",
       "415        0       0       0       1       0       0       1       0       0   \n",
       "880        0       0       0       1       0       0       1       0       0   \n",
       "1201       0       0       0       0       0       0       0       0       1   \n",
       "\n",
       "      TA0009  TA0011  TA0001  \n",
       "319        0       0       0  \n",
       "336        0       0       0  \n",
       "1077       0       0       0  \n",
       "486        0       0       0  \n",
       "371        0       0       0  \n",
       "...      ...     ...     ...  \n",
       "1477       0       0       0  \n",
       "1376       0       0       0  \n",
       "415        0       0       0  \n",
       "880        0       1       0  \n",
       "1201       0       0       0  \n",
       "\n",
       "[441 rows x 12 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_tactic_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "16dc519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred_tactic = pd.DataFrame(tactic_model.predict(X_test_tactic_pickle), columns = Y_test_tactic.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9ca5d",
   "metadata": {},
   "source": [
    "# Hanging Node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tactics and list of techniques:\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe37230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tactic_prob = pd.DataFrame(tactic_model.decision_function(X_test_tactic), columns=Y_test_tactic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8272a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if scaling at (-1,1) then threshold of .5 \n",
    "# scaling determines improvement \n",
    "# (0-1) performs poorly with threshold of .5 \n",
    "\n",
    "technique_prob = pd.DataFrame(MinMaxScaler((-1, 1)).fit_transform(sv_classifier.decision_function(X_test)), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c512995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hanging_node(i, tactic_proba, technique_proba,tactic_threshold=0.5, technique_threshold=0.5, a = 1,b = 0, c=1, d=0):\n",
    "    assert a > technique_threshold and c > technique_threshold and b < tactic_threshold and d < tactic_threshold\n",
    "    pred_tactics = [tactic for tactic in tactic_proba.columns if tactic_proba.iloc[i][tactic] > tactic_threshold]\n",
    "    pred_techniques = [technique for technique in technique_proba.columns if technique_proba.iloc[i][technique] > technique_threshold]\n",
    "    #return pred_tactics, pred_techniques\n",
    "    print((pred_tactics, pred_techniques))\n",
    "    for tactic in tactic_proba.columns:\n",
    "        for technique in tactic_data[tactic]['Technique_ID'][0]:\n",
    "            if technique in pred_techniques and tactic not in pred_tactics:\n",
    "                if technique_proba.iloc[i][technique] > a and tactic_proba.iloc[i][tactic] > b:\n",
    "                    pred_tactics.append(tactic)\n",
    "                elif technique_proba.iloc[i][technique] < c and tactic_proba.iloc[i][tactic] < d:\n",
    "                    pred_techniques.remove(technique)\n",
    "    print(pred_tactics, pred_techniques)\n",
    "    print('-----------------------------')\n",
    "    return pred_tactics, pred_techniques\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_tactics_hanging_node = []\n",
    "Y_test_techniques_hanging_node = []\n",
    "for i in range(len(X_test)):\n",
    "    pred_tactics, pred_techniques = hanging_node(i, tactic_prob, technique_prob,tactic_threshold=0, technique_threshold=0.5,  a = 0.55, b = -0.9, c = 0.95, d = -0.30)\n",
    "    Y_test_tactics_hanging_node.append([1 if tactic in pred_tactics else 0 for tactic in Y_test_tactic.columns])\n",
    "    Y_test_techniques_hanging_node.append([1 if technique in pred_techniques else 0 for technique in Y_test.columns])\n",
    "\n",
    "Y_test_tactics_hanging_node = pd.DataFrame(Y_test_tactics_hanging_node, columns=Y_test_tactic.columns)\n",
    "Y_test_techniques_hanging_node = pd.DataFrame(Y_test_techniques_hanging_node, columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0bd8e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Y_pred, Y_test):\n",
    "    macro_precision = precision_score(Y_test, Y_pred, average ='macro')\n",
    "    micro_precision = precision_score(Y_test, Y_pred, average ='micro')\n",
    "    macro_recall = recall_score(Y_test, Y_pred, average='macro')\n",
    "    micro_recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "    macro_fscore = fbeta_score(Y_test, Y_pred, beta=0.5, average ='macro')\n",
    "    micro_fscore = fbeta_score(Y_test, Y_pred, beta=0.5, average ='micro')\n",
    "    l_metric = ['macro precision', 'micro precision', 'macro recall', 'micro recall', 'macro fscore', 'micro fscore']\n",
    "    l_result = [macro_precision, micro_precision, macro_recall, micro_recall, macro_fscore, micro_fscore]\n",
    "    df_res = pd.DataFrame({'metric': l_metric, 'result': l_result})\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222128c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_test_tactics_hanging_node, Y_test_tactic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_test_techniques_hanging_node, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979199a0",
   "metadata": {},
   "source": [
    "# Train Model on Reports Tactics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if training on only techniques improves or not\n",
    "# only train techniques on reports belonging to a techniques' tactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b5a2b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key as technique, value as tactic.\n",
    "\n",
    "from collections import defaultdict\n",
    "tactic_to_technique = defaultdict(list)\n",
    "for tactic in tactic_data:\n",
    "    for technique in tactic_data[tactic]['Technique_ID'][0]:\n",
    "        if tactic in Y_train_tactic.columns:\n",
    "            tactic_to_technique[technique].append(tactic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b28caf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for matching between tactic and technique\n",
    "# find technique that are not in dictionary. \n",
    "# for Y_r, find report that only contains that technique and find what tactics is has \n",
    "\n",
    "for technique in Y_train.columns:\n",
    "    if technique not in tactic_to_technique:\n",
    "        index = Y_r[(Y_r.sum(axis=1)==1) & (Y_r[technique] == 1)].index[0]\n",
    "        tacics = [tactic for tactic in Y_train_tactic.columns if \n",
    "                       int(Y_r_tactic.loc[index, tactic])==1]\n",
    "        tactic_to_technique[technique] = tacics\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4682874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "for technique in Y_train.columns:\n",
    "    indexes = Y_train_tactic[Y_train_tactic.apply(lambda x: any(x[tactic] ==1 for tactic in tactic_to_technique[technique]), axis=1)].index\n",
    "    X_train_technique = X_train.loc[indexes]\n",
    "    Y_train_technique = Y_train.loc[indexes, technique]\n",
    "    clf = LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 1000, class_weight = 'balanced', random_state=42)\n",
    "    clf.fit(X_train_technique, Y_train_technique)\n",
    "    classifiers.append(clf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fa352cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(0, index=X_test.index, columns=Y_test.columns)\n",
    "for i, technique in enumerate(Y_test.columns):\n",
    "    indexes = Y_test_pred_tactic[Y_test_pred_tactic.apply(lambda x: any(x[tactic] ==1 for tactic in tactic_to_technique[technique]), axis=1)].index\n",
    "    Y_pred.loc[indexes, technique] = classifiers[i].predict(X_test.loc[indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1d5a56d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/vol/bitbucket/lgf21/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>macro precision</td>\n",
       "      <td>0.499174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro precision</td>\n",
       "      <td>0.505065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro recall</td>\n",
       "      <td>0.341547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro recall</td>\n",
       "      <td>0.401380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro fscore</td>\n",
       "      <td>0.429969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro fscore</td>\n",
       "      <td>0.480253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric    result\n",
       "0  macro precision  0.499174\n",
       "1  micro precision  0.505065\n",
       "2     macro recall  0.341547\n",
       "3     micro recall  0.401380\n",
       "4     macro fscore  0.429969\n",
       "5     micro fscore  0.480253"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(Y_pred, Y_test) # performance for technique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08735f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
